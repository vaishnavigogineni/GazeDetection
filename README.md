
# Gaze Tracking and Crowd Analysis with Face Recognition

Welcome to the Gaze Tracking and Crowd Analysis project! This repository contains code for a Python application that analyzes video streams to track gaze behavior, detect faces, and perform crowd analysis using advanced face recognition techniques.


## Project Overview

The Gaze Tracking and Crowd Analysis project is designed to provide comprehensive insights into human interaction with visual content. By leveraging cutting-edge face recognition algorithms and computer vision techniques, the application offers a wide range of functionalities, including:

- Gaze Tracking: Precisely tracks the movement of a person's gaze within a video stream, enabling analysis of visual attention patterns and direction of focus.

- Facial Recognition: Detects and recognizes faces within the video feed, extracting facial landmarks and performing gaze analysis to understand human behavior.

- Crowd Analysis: Counts the number of distinct faces present in each frame of the video, facilitating crowd enumeration and demographic analysis.

- Face Detection: Utilizes dlib's pre-trained face detector to locate faces within the video stream.

- Facial Landmark Extraction: Predicts facial landmarks, including eye positions, nose contours, and mouth shapes, enabling precise tracking of facial features.

## Libraries Used

- OpenCV: Used for image processing tasks, including face detection, landmark extraction, and frame manipulation.

- dlib: Utilized for its facial recognition capabilities, including face detection and landmark prediction.
- NumPy: Employed for efficient array manipulation and mathematical operations.
- Math: Used for mathematical computations, such as calculating distances and ratios.

## OUTPUT AFTER EXAMPLE VIDEO STREAM 
<img width="828" alt="image" src="https://github.com/vaishnavigogineni/GazeDetection/assets/94545751/059dad8d-86e0-4a0d-90a9-66ae08fb24a4">

## ACCESS LINK FOR THE .DAT FILE
https://drive.google.com/file/d/1yAdGwGcaFuFdfxAd_obRxOZDxadzHpLA/view?usp=drivesdk

This has been integrated into a online AI interview co-pilot and results can be seen as:
<img width="853" alt="image" src="https://github.com/vaishnavigogineni/GazeDetection/assets/94545751/505541f6-8fab-4206-82cd-40827797a9ec">

## Getting Started

Clone the repository to your local machine.

Install the required dependencies by running pip install -r requirements.txt.

Run the main script to start analyzing video streams and tracking gaze behavior.


## License

[MIT](https://choosealicense.com/licenses/mit/)

